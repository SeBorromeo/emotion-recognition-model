{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQb_AHyogru3"
      },
      "source": [
        "# CS 4501: Computer Vision -- Detecting Human Emotions through Videos\n",
        "### Akira Durham (zup9su) and Sebastian Borromeo (uwg3xs)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "SNoVgze1kIUR"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Methods"
      ],
      "metadata": {
        "id": "62kHBWy54ykj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://pytorch.org/tutorials/beginner/data_loading_tutorial.html"
      ],
      "metadata": {
        "id": "LvlCaXZn4ykj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ProcessData(Dataset):\n",
        "    def __init__(self, data, labels):\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5,), (0.5,))\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        data = Image.fromarray(self.data[idx])\n",
        "        label = self.labels[idx]\n",
        "        data = self.transform(data)\n",
        "\n",
        "        return data, label"
      ],
      "metadata": {
        "id": "lhsl6jOZ4ykk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_accuracy(logit, target, batch_size):\n",
        "    \"\"\"Obtain accuracy for training round\"\"\"\n",
        "    corrects = (torch.max(logit, 1)[1].view(target.size()).data == target.data).sum()\n",
        "    ret_acc = 100.0 * corrects / batch_size\n",
        "    return ret_acc.item()"
      ],
      "metadata": {
        "id": "qq4Dstk8-DkK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Processing"
      ],
      "metadata": {
        "id": "b4onJVzqjfqj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data was pulled from https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge/data, which is FER2013's Kaggle competition, providing separated training and test datasets already."
      ],
      "metadata": {
        "id": "2y4V-vjbomo4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "num_epochs = 10\n",
        "batch_size = 64\n",
        "learning_rate = 0.001"
      ],
      "metadata": {
        "id": "ebPatGP4yg2g"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load in .csv\n",
        "input_data = np.loadtxt('fer2013.csv', delimiter=',', skiprows=1, dtype=str)"
      ],
      "metadata": {
        "id": "xgPGLjuEjelX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extract emotion labels\n",
        "all_labels = input_data[:, 0].astype(int)"
      ],
      "metadata": {
        "id": "kJUhaUYqz1Xq"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create np array from stacked pixel vals + ensure sizing\n",
        "pixel_data = np.array([np.fromstring(row, dtype=np.uint8, sep=' ') for row in input_data[:, 1]])\n",
        "pixel_data = pixel_data.reshape(-1, 48, 48)"
      ],
      "metadata": {
        "id": "kHpGnr3zxaTx"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get indices from input_data\n",
        "train_indices = np.where(input_data[:, 2] == 'Training')[0]\n",
        "test_indices = np.where(input_data[:, 2] == 'PublicTest')[0]"
      ],
      "metadata": {
        "id": "fEAONYho1bFY"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create datasets using custom class\n",
        "train_set = ProcessData(pixel_data[train_indices], all_labels[train_indices])\n",
        "test_set = ProcessData(pixel_data[test_indices], all_labels[test_indices])"
      ],
      "metadata": {
        "id": "0woBEQw13Ji-"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create dataloaders for train iterations and batching\n",
        "train = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "test = DataLoader(test_set, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "mCrpXD5f3Ona"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN Model Building"
      ],
      "metadata": {
        "id": "jDB3dVA-jmeg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128*6*6, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(256, 7)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "class CNN2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN2, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Dropout(0.25),\n",
        "\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Dropout(0.25),\n",
        "\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128 * 6 * 6, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(1024, 7)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# https://debuggercafe.com/implementing-vgg11-from-scratch-using-pytorch/\n",
        "class CNN3(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN3, self).__init__()\n",
        "        # should this have batch normalization?\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, kernel_size=3, padding=1),\n",
        "            # nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            # nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            # nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            # nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
        "            # nn.BatchNorm2d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            # nn.BatchNorm2d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            # nn.BatchNorm2d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            # nn.BatchNorm2d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(512 * 7 * 7, 4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "\n",
        "            nn.Linear(4096, 7)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ],
      "metadata": {
        "id": "JzsNvskljvXb"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "YORqUo2Djvyk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = CNN().to(device)\n",
        "model.train()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "qvU71NsJjx4J"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    train_running_loss = 0.0\n",
        "    train_acc = 0.0\n",
        "\n",
        "    for images, labels in train:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        logits = model(images)\n",
        "        loss = criterion(logits, labels)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_running_loss += loss.detach().item()\n",
        "        train_acc += get_accuracy(logits, labels, batch_size)\n",
        "\n",
        "    print('Epoch: %d | Loss: %.4f | Train Accuracy: %.2f' % (epoch, train_running_loss / len(train), train_acc / len(train)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5fsUG1f5a0S",
        "outputId": "16b10953-25c2-42bb-da20-3d16240fa10c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 | Loss: 1.6485 | Train Accuracy: 35.29\n",
            "Epoch: 1 | Loss: 1.3935 | Train Accuracy: 46.11\n",
            "Epoch: 2 | Loss: 1.2914 | Train Accuracy: 50.38\n",
            "Epoch: 3 | Loss: 1.2168 | Train Accuracy: 53.48\n",
            "Epoch: 4 | Loss: 1.1536 | Train Accuracy: 55.70\n",
            "Epoch: 5 | Loss: 1.0967 | Train Accuracy: 58.00\n",
            "Epoch: 6 | Loss: 1.0482 | Train Accuracy: 59.67\n",
            "Epoch: 7 | Loss: 0.9896 | Train Accuracy: 62.04\n",
            "Epoch: 8 | Loss: 0.9422 | Train Accuracy: 63.83\n",
            "Epoch: 9 | Loss: 0.8837 | Train Accuracy: 65.91\n",
            "Epoch: 10 | Loss: 0.8338 | Train Accuracy: 67.75\n",
            "Epoch: 11 | Loss: 0.7682 | Train Accuracy: 70.38\n",
            "Epoch: 12 | Loss: 0.7283 | Train Accuracy: 71.83\n",
            "Epoch: 13 | Loss: 0.6764 | Train Accuracy: 73.92\n",
            "Epoch: 14 | Loss: 0.6311 | Train Accuracy: 75.61\n",
            "Epoch: 15 | Loss: 0.5848 | Train Accuracy: 77.22\n",
            "Epoch: 16 | Loss: 0.5508 | Train Accuracy: 78.58\n",
            "Epoch: 17 | Loss: 0.5176 | Train Accuracy: 79.90\n",
            "Epoch: 18 | Loss: 0.4836 | Train Accuracy: 81.17\n",
            "Epoch: 19 | Loss: 0.4598 | Train Accuracy: 82.06\n",
            "Epoch: 20 | Loss: 0.4349 | Train Accuracy: 82.89\n",
            "Epoch: 21 | Loss: 0.4223 | Train Accuracy: 83.35\n",
            "Epoch: 22 | Loss: 0.3980 | Train Accuracy: 84.41\n",
            "Epoch: 23 | Loss: 0.3896 | Train Accuracy: 84.72\n",
            "Epoch: 24 | Loss: 0.3672 | Train Accuracy: 85.64\n",
            "Epoch: 25 | Loss: 0.3531 | Train Accuracy: 85.86\n",
            "Epoch: 26 | Loss: 0.3321 | Train Accuracy: 86.84\n",
            "Epoch: 27 | Loss: 0.3230 | Train Accuracy: 87.29\n",
            "Epoch: 28 | Loss: 0.3153 | Train Accuracy: 87.73\n",
            "Epoch: 29 | Loss: 0.3102 | Train Accuracy: 87.85\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'model.pth')\n",
        "# model = CNN()\n",
        "# model.load_state_dict(torch.load('model.pth', weights_only=True))"
      ],
      "metadata": {
        "id": "HzxhEu1eDODB"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing"
      ],
      "metadata": {
        "id": "sWT_CXW3jzRQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "test_acc = 0.0\n",
        "output = []\n",
        "\n",
        "for images, labels in test:\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "    logits = model(images)\n",
        "    test_acc += get_accuracy(logits, labels, batch_size)\n",
        "    output.extend(torch.argmax(logits, dim=1).cpu().numpy())\n",
        "\n",
        "print('Test Accuracy: %.2f' % (test_acc / len(test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMrYLvzzAlUk",
        "outputId": "aa08ab62-4112-406f-81c4-4e258e2382d6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 56.88\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Video Section"
      ],
      "metadata": {
        "id": "wAcnHhh5Nsa4"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZOBknYbANvva"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}